{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b55c6b0-a531-484d-be51-29fd7d95e989",
   "metadata": {},
   "source": [
    "<font size=7>Reliability of the salience features and object categories<font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abeed6b-f2c9-4f1e-97e1-8c26f1f6e3d7",
   "metadata": {},
   "source": [
    "<font size=3>Finally, we want to look at the split-half reliability of the salience features and the object categories in our data set. Each file contains two columns for the values from even and odd images, each row contains the data of one subject. Calculate the split-half reliability for all saliency features and object categories. How do you assess the reliabilities?<font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "831b081a-99e8-4ec9-8e24-616a4827bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import scipy.io\n",
    "import scipy.stats\n",
    "from scipy.ndimage import gaussian_filter\n",
    "#from ipywidgets import interact, Button\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from PIL import Image\n",
    "#import solara\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RESULTS_FOLDER_FIX = 'data_task_C/data_fix/'\n",
    "RESULTS_FOLDER_SACC = 'data_task_C/data_sacc/'\n",
    "SALIENCY_MAP_DICT = 'data_task_F/saliency_map_dict.npy'\n",
    "OSIE_FILE = 'data_task_F/attrs_OSIE_40.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c30fa706-aa82-4869-bc9e-160f289fa339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_semantic_saliency_fix(subject_num):\n",
    "    # Add necessary path\n",
    "    fix_data_path = (\n",
    "        #\"/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Task_C/data/derivatives/\"\n",
    "        RESULTS_FOLDER_FIX\n",
    "        + subject_num\n",
    "        + \"_fix_data.csv\"\n",
    "    )\n",
    "\n",
    "    OSIE_data_path = OSIE_FILE#\"/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Task_C/OSIE_40/attrs_OSIE_40.mat\"\n",
    "\n",
    "    saliency_map_path = SALIENCY_MAP_DICT#\"/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Task_C/OSIE_40/saliency_map_dict.npy\"\n",
    "\n",
    "    # Load the MATLAB .mat file containing the data\n",
    "    fix_data = pd.read_csv(fix_data_path, sep=\",\")\n",
    "    # mat_data = loadmat(OSIE_data_path)\n",
    "    mat_dict = loadmat(OSIE_data_path, simplify_cells=True)\n",
    "    attrs_OSIE_40 = mat_dict[\"attrs_OSIE_40\"]\n",
    "    saliency_map_dict = np.load(\n",
    "        saliency_map_path,\n",
    "        allow_pickle=\"TRUE\",\n",
    "    ).item()\n",
    "\n",
    "    # print(saliency_map_dict)\n",
    "    # df = pd.read_table(\"/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Task_C/pilot_res/pp_scan_2024_03_21_16_08.asc\")\n",
    "    # ascii_grid = np.loadtxt(\"/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Task_C/pilot_res/pp_scan_2024_03_21_16_08.asc\", skiprows=100)\n",
    "\n",
    "    # Constants and parameters\n",
    "    dims = [0, 1, 5, 7, 10]\n",
    "    # Header = [\"Text\", \"Face\", \"Taste\", \"Motion\", \"Touched\"]\n",
    "\n",
    "    im_width, im_height = 800, 600\n",
    "\n",
    "    im_width_real, im_height_real = 1146, 876  # real size\n",
    "    exp_scale_width = im_width_real / im_width  # 1.4325\n",
    "    exp_scale_height = im_height_real / im_height  # 1.46\n",
    "    screen_width, screen_height = 1920, 1080\n",
    "    # screen_x_cm, screen_y_cm, vp_dist_cm = 51.5, 29.0, 60\n",
    "    # sample_freq = 1000\n",
    "    # XPIX2DEG = np.arctan((screen_x_cm / screen_width) / vp_dist_cm) * (180 / np.pi)\n",
    "    # YPIX2DEG = np.arctan((screen_y_cm / screen_height) / vp_dist_cm) * (180 / np.pi)\n",
    "    # folder_name = f\"e1v{subject_num}b1\"\n",
    "    fixations = {}\n",
    "\n",
    "    # im_num = '1001.jpg'\n",
    "    # block_num = 1\n",
    "\n",
    "    BLOCK_NUMS = 40\n",
    "    for block_num in range(0, BLOCK_NUMS):\n",
    "        # block_num = 1\n",
    "        image_name = attrs_OSIE_40[block_num][\"img\"]\n",
    "        # objs = attrs_OSIE_40[block_num][\"objs\"]\n",
    "\n",
    "        fix_data_block = fix_data[fix_data[\"img\"] == image_name]\n",
    "        Cfix = len(fix_data_block)  # fixation count\n",
    "        Dfix = list(fix_data_block[\"dur\"])  # fixation durations\n",
    "        Xfix = list(\n",
    "            ((fix_data_block[\"axp\"] - (screen_width / 2)) / exp_scale_width) + (im_width / 2)\n",
    "        )\n",
    "        # Xfix = Xfix - (screen_width/2) #/ exp_scale_width)\n",
    "        # Xfix = Xfix + (im_width/2)\n",
    "        # Xfix_norm = Xfix/exp_scale_width # X coord\n",
    "        Yfix = list(\n",
    "            ((fix_data_block[\"ayp\"] - (screen_height / 2)) / exp_scale_height) + (im_height / 2)\n",
    "        )  # / exp_scale_height)  # Y coord\n",
    "        Order = list(fix_data_block[\"fix_order\"])\n",
    "        # for im_num in pd.unique(fix_data['img']):\n",
    "\n",
    "        # Analyze semantic content\n",
    "        sem = np.zeros((Cfix, len(dims)))\n",
    "\n",
    "        for d in range(len(dims)):\n",
    "            map_sum = np.zeros((im_height, im_width))\n",
    "            # map_ori = []\n",
    "            for obj in range(len(attrs_OSIE_40[block_num][\"objs\"])):\n",
    "                # obj = 0\n",
    "                if attrs_OSIE_40[block_num][\"objs\"][obj][\"features\"][dims[d]] > 0:\n",
    "                    # print(attrs_OSIE_40[block_num-1]['objs'][obj]['features'][dims[d]])\n",
    "                    map_ori = attrs_OSIE_40[block_num][\"objs\"][obj][\"map\"]\n",
    "                    # print(map_ori)\n",
    "                    map_sum += map_ori\n",
    "                    # print(map_sum)\n",
    "            for f in range(Cfix):\n",
    "                sem[f, d] = 0\n",
    "                if 0 < round(Xfix[f]) <= im_width and 0 < round(Yfix[f]) <= im_height:\n",
    "                    sem[f, d] = map_sum[int(round(Yfix[f])), int(round(Xfix[f]))] * Dfix[f]\n",
    "\n",
    "        sem_df = pd.DataFrame(sem)\n",
    "\n",
    "        # Analyze saliency content\n",
    "        sal = np.zeros((Cfix, len(saliency_map_dict[image_name])))\n",
    "        list_of_sal_maps = list(saliency_map_dict[image_name].keys())\n",
    "\n",
    "        for i, sal_map in enumerate(list_of_sal_maps):\n",
    "            # print(i, sal_map)\n",
    "            sal_map_ori = saliency_map_dict[image_name][sal_map]\n",
    "\n",
    "            for f in range(Cfix):\n",
    "                sal[f, i] = 0\n",
    "                if 0 < round(Xfix[f]) <= im_width and 0 < round(Yfix[f]) <= im_height:\n",
    "                    # sal[f, i] = sal_map_ori[int(round(Yfix[f])), int(round(Xfix[f]))] * Dfix[f]\n",
    "                    sal[f, i] = (\n",
    "                        np.sum(sal_map_ori < sal_map_ori[int(round(Yfix[f])), int(round(Xfix[f]))])\n",
    "                        / sal_map_ori.size\n",
    "                    )  # * Dfix[f]\n",
    "\n",
    "        sal_df = pd.DataFrame(sal, columns=list_of_sal_maps)\n",
    "\n",
    "        fixations[image_name] = {\n",
    "            \"X\": Xfix,\n",
    "            \"Y\": Yfix,\n",
    "            # \"Onset\": Tfix,\n",
    "            \"Duration\": Dfix,\n",
    "            # \"Amplitude\": Asac,\n",
    "            \"Sem\": sem_df,\n",
    "            \"Sal\": sal_df,\n",
    "            \"Order\": Order,\n",
    "        }\n",
    "\n",
    "    return fixations\n",
    "\n",
    "\n",
    "\n",
    "def extract_fix_split_half():\n",
    "    # fixations_odd = {}\n",
    "    # fixations_even = {}\n",
    "    fix_dataframe_group = pd.DataFrame()\n",
    "    subject_list = [\"zt\", \"pp\", \"jp\"]\n",
    "    for subject_num in subject_list:\n",
    "        # subject_num='zt'\n",
    "        # fixations = extract_semantic_fix(subject_num)\n",
    "        fixations = extract_semantic_saliency_fix(subject_num)\n",
    "        # Constants and parameters\n",
    "        dims = [0, 1, 5, 7, 10]\n",
    "        header_sem1 = [\"Text1\", \"Face1\", \"Taste1\", \"Motion1\", \"Touched1\"]\n",
    "        header_sal1 = [\"Saliency1\", \"Intensity1\", \"Color1\", \"Orientation1\"]\n",
    "        header_sem2 = [\"Text2\", \"Face2\", \"Taste2\", \"Motion2\", \"Touched2\"]\n",
    "        header_sal2 = [\"Saliency2\", \"Intensity2\", \"Color2\", \"Orientation2\"]\n",
    "        header_tot = header_sem1 + header_sem2 + header_sal1 + header_sal2\n",
    "\n",
    "        first_fix = []\n",
    "        all_fix_sem_1 = pd.DataFrame()\n",
    "        all_fix_sal_1 = pd.DataFrame()\n",
    "        all_fix_sem_2 = pd.DataFrame()\n",
    "        all_fix_sal_2 = pd.DataFrame()\n",
    "        # d_fix = []\n",
    "        all_dur_1 = []  # pd.DataFrame()\n",
    "        all_dur_2 = []\n",
    "        fixation_keys = list(fixations.keys())\n",
    "\n",
    "        for i, key in enumerate(fixation_keys):\n",
    "            # key = '1001.jpg'\n",
    "            if fixations[key] is not None:\n",
    "                # sem\n",
    "                df_sem = pd.DataFrame(fixations[key][\"Sem\"])\n",
    "                df_sal = fixations[key][\"Sal\"]\n",
    "                df_dur = fixations[key][\"Duration\"]\n",
    "\n",
    "                if i % 2 == 0:\n",
    "                    all_fix_sem_2 = pd.concat([all_fix_sem_2, df_sem])\n",
    "                    all_dur_2 += df_dur\n",
    "                    all_fix_sal_2 = pd.concat([all_fix_sal_2, df_sal])\n",
    "\n",
    "                else:\n",
    "                    all_fix_sem_1 = pd.concat([all_fix_sem_1, df_sem])\n",
    "                    all_dur_1 += df_dur\n",
    "                    all_fix_sal_1 = pd.concat([all_fix_sal_1, df_sal])\n",
    "\n",
    "        # first_prop = np.sum(np.sign(first_fix), axis=0) / len(first_fix)\n",
    "        # all_prop = np.sum(all_fix, axis=0) / np.sum(d_fix)\n",
    "        all_prop_sem_1 = all_fix_sem_1.sum() / sum(all_dur_1)\n",
    "        all_prop_sem_2 = all_fix_sem_2.sum() / sum(all_dur_2)\n",
    "        all_prop_sal_1 = all_fix_sal_1.mean()\n",
    "        all_prop_sal_2 = all_fix_sal_2.mean()\n",
    "\n",
    "        # sem_fix_data = pd.DataFrame((np.array(header), first_prop, np.array(all_prop))).T.rename(columns={0:'header', 1:'first_prop', 2:'all_prop'})\n",
    "        fix_data_ind = {\n",
    "            # \"header\": header_sem1 + header_sem2 + header_sal1 + header_sal2,\n",
    "            # \"first_prop\": list(first_prop),\n",
    "            \"all_prop\": list(all_prop_sem_1)\n",
    "            + list(all_prop_sem_2)\n",
    "            + list(all_prop_sal_1)\n",
    "            + list(all_prop_sal_2),\n",
    "        }\n",
    "        fix_dataframe_ind = pd.DataFrame.from_dict(\n",
    "            fix_data_ind, orient=\"index\", columns=header_tot\n",
    "        )  # , columns=[\"header\", \"all_prop\"]).T\n",
    "        fix_dataframe_ind[\"sub_num\"] = subject_num\n",
    "        # fix_dataframe_ind(columns=\"header\")\n",
    "        fix_dataframe_group = pd.concat([fix_dataframe_group, fix_dataframe_ind])\n",
    "        \n",
    "    return fix_dataframe_group\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efa1c3d3-0fa4-4963-ba3b-12010a02d742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Text1     Face1    Taste1   Motion1  Touched1     Text2  \\\n",
      "all_prop  0.088915  0.411927  0.090332  0.303647  0.101175  0.156961   \n",
      "all_prop  0.025727  0.139064  0.189396  0.203593  0.059777  0.074578   \n",
      "all_prop  0.098437  0.218040  0.123872  0.218894  0.117594  0.171854   \n",
      "\n",
      "             Face2    Taste2   Motion2  Touched2  Saliency1  Intensity1  \\\n",
      "all_prop  0.418974  0.041790  0.243774  0.136339   0.663116    0.660642   \n",
      "all_prop  0.132261  0.041072  0.180172  0.065554   0.675862    0.661572   \n",
      "all_prop  0.321564  0.043318  0.196337  0.101642   0.645369    0.632767   \n",
      "\n",
      "            Color1  Orientation1  Saliency2  Intensity2    Color2  \\\n",
      "all_prop  0.560854      0.682619   0.677480    0.639840  0.572125   \n",
      "all_prop  0.573157      0.693457   0.662665    0.621600  0.588453   \n",
      "all_prop  0.555469      0.683669   0.660444    0.654477  0.543115   \n",
      "\n",
      "          Orientation2 sub_num  \n",
      "all_prop      0.695812      zt  \n",
      "all_prop      0.654590      pp  \n",
      "all_prop      0.682514      jp  \n"
     ]
    }
   ],
   "source": [
    "df = extract_fix_split_half()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "330f4f08-e05f-41db-a55b-1475fc71a91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_prop    0.560854\n",
      "all_prop    0.573157\n",
      "all_prop    0.555469\n",
      "Name: Color1, dtype: float64\n",
      "0.9278293743636787 0.24334507513265086\n",
      "0.9625637898270211\n"
     ]
    }
   ],
   "source": [
    "Color1 = df['Color1']\n",
    "Color2 = df['Color2']\n",
    "print(Color1)\n",
    "\n",
    "R_col, p_col = scipy.stats.pearsonr(Color1, Color2)\n",
    "print(R_col, p_col)\n",
    "\n",
    "\n",
    "reliability = (2*R_col)/(1+R_col)\n",
    "print(reliability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6270006-0598-4307-a1eb-a9a48c93f00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_prop    0.682619\n",
      "all_prop    0.693457\n",
      "all_prop    0.683669\n",
      "Name: Orientation1, dtype: float64 all_prop    0.695812\n",
      "all_prop    0.654590\n",
      "all_prop    0.682514\n",
      "Name: Orientation2, dtype: float64\n",
      "-0.972836525216547 0.14872219778771217\n",
      "-71.62828268268255\n"
     ]
    }
   ],
   "source": [
    "Ori1 = df['Orientation1']\n",
    "Ori2 = df['Orientation2']\n",
    "print(Ori1, Ori2)\n",
    "\n",
    "R_col, p_col = scipy.stats.pearsonr(Ori1, Ori2)\n",
    "print(R_col, p_col)\n",
    "\n",
    "\n",
    "reliability = (2*R_col)/(1+R_col)\n",
    "print(reliability)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
