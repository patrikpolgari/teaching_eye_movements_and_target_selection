{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f6e287-d8db-4133-a60e-ea765503f8f9",
   "metadata": {},
   "source": [
    "<font size=7>Comparison with the whole group<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941f970d-bbf9-4552-9cf4-a5cc3da3f385",
   "metadata": {},
   "source": [
    "<font size=5>Step 1: Group averages\n",
    "\n",
    "<font size=3>You can now compare your results with the data of the entire group.\n",
    "\n",
    "<font size=3>•\tAre there common effects in the whole group? \n",
    "\n",
    "<font size=3>•\tWhere do individual differences become apparent?\n",
    "\n",
    "<font size=3>•\tWhere do you place yourself in the group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd73d310-41db-4ac2-ba98-d93d7d1638a4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8l/8mhtfcfd3kx35x8ns523w5zm0000gn/T/ipykernel_71713/4149269328.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Jupyter\n",
      "['zt', 'jp', 'pp']\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import scipy.io\n",
    "from scipy.stats import norm\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from PIL import Image\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import cv2\n",
    "import ITTISaliencyLib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#im_width, im_height = 800, 600\n",
    "#im_width_real, im_height_real = 1146, 876  # real size\n",
    "#exp_scale_width = im_width_real / im_width  # 1.4325\n",
    "#exp_scale_height = im_height_real / im_height  # 1.46\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "# Path to the folder containing JPG images\n",
    "#IMAGE_FOLDER = '/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Jupyter/images_task_F/images'\n",
    "IMAGE_FOLDER = 'images_task_F'\n",
    "#RESULTS_FOLDER = '/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Task_C/data/pilot_res'\n",
    "RESULTS_FOLDER_FIX = 'data_task_C/data_fix/'\n",
    "RESULTS_FOLDER_SACC = 'data_task_C/data_sacc/'\n",
    "#SALIENCY_MAP_DICT = 'data_task_F/saliency_map_dict.npy'\n",
    "OSIE_FILE = 'data_task_F/attrs_OSIE_40.mat'\n",
    "# Get a list of JPG image files in the folder\n",
    "image_files = [f for f in os.listdir(IMAGE_FOLDER) if f.endswith('.jpg')]\n",
    "SUBJECT_LIST = [sub[:2] for sub in os.listdir(RESULTS_FOLDER_FIX)if sub != '.DS_Store']\n",
    "print(SUBJECT_LIST)\n",
    "#subject_list = ['zt', 'pp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93230c09-a239-4d17-af64-89661c96f024",
   "metadata": {},
   "source": [
    "***The cell below might take a long time to execute:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a17268-05e9-444b-8a25-7f8999360575",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_saliency_map_dict():\n",
    "    #images_path = \"/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Task_C/OSIE_40/images\"\n",
    "    #image_list = []\n",
    "\n",
    "    #os.chdir(images_path)\n",
    "    #os.chdir(IMAGE_FOLDER)\n",
    "    #for file in glob.glob(\"*.jpg\"):\n",
    "    #    image_list.append(file)\n",
    "\n",
    "    saliency_map_dict = {}\n",
    "\n",
    "    #for image_name in image_list:\n",
    "    for image_name in image_files:\n",
    "        img = cv2.imread(os.path.join(IMAGE_FOLDER,image_name))\n",
    "        saliency_map_dict[image_name] = {}\n",
    "\n",
    "        # image_num = image_name[0:4]\n",
    "        # initialize\n",
    "        # imgsize = img.shape\n",
    "        # img_width = imgsize[1]\n",
    "        # img_height = imgsize[0]\n",
    "        # sm = pySaliencyMap.pySaliencyMap(img_width, img_height)\n",
    "        # computation of saliency maps\n",
    "        saliency_map = ITTISaliencyLib.get_spatial_saliency_map(img)\n",
    "        saliency_map_intensity = ITTISaliencyLib.get_spatial_saliency_map_I(img)\n",
    "        saliency_map_color = ITTISaliencyLib.get_spatial_saliency_map_C(img)\n",
    "        saliency_map_orientation = ITTISaliencyLib.get_spatial_saliency_map_O(img)\n",
    "\n",
    "        list_of_maps = [\n",
    "            (\"saliency_map\", saliency_map),\n",
    "            (\"saliency_map_intensity\", saliency_map_intensity),\n",
    "            (\"saliency_map_color\", saliency_map_color),\n",
    "            (\"saliency_map_orientation\", saliency_map_orientation),\n",
    "        ]\n",
    "\n",
    "        saliency_map_dict[image_name].update(list_of_maps)\n",
    "\n",
    "    return saliency_map_dict\n",
    "\n",
    "SALIENCY_MAP_DICT = make_saliency_map_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae400f7-4da9-4657-a8ac-dbdb5e6449d8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_semantic_fix(subject_num):\n",
    "    # Add necessary path\n",
    "    fix_data_path = (\n",
    "        #\"/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Task_C/data/derivatives/\"\n",
    "        RESULTS_FOLDER_FIX\n",
    "        + subject_num\n",
    "        + \"_fix_data.csv\"\n",
    "    )\n",
    "\n",
    "    #OSIE_data_path = \"/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Task_C/OSIE_40/attrs_OSIE_40.mat\"\n",
    "    #OSIE_data_path = \"/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Task_C/OSIE_40/attrs_OSIE_40.mat\"\n",
    "    OSIE_data_path = OSIE_FILE\n",
    "    # Load the MATLAB .mat file containing the data\n",
    "    fix_data = pd.read_csv(fix_data_path, sep=\",\")\n",
    "    # mat_data = loadmat(OSIE_data_path)\n",
    "    mat_dict = loadmat(OSIE_data_path, simplify_cells=True)\n",
    "    # df = pd.read_table(\"/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Task_C/pilot_res/pp_scan_2024_03_21_16_08.asc\")\n",
    "    # ascii_grid = np.loadtxt(\"/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Task_C/pilot_res/pp_scan_2024_03_21_16_08.asc\", skiprows=100)\n",
    "    attrs_OSIE_40 = mat_dict[\"attrs_OSIE_40\"]\n",
    "\n",
    "    # Constants and parameters\n",
    "    dims = [0, 1, 5, 7, 10]\n",
    "    # Header = [\"Text\", \"Face\", \"Taste\", \"Motion\", \"Touched\"]\n",
    "\n",
    "    im_width, im_height = 800, 600\n",
    "\n",
    "    im_width_real, im_height_real = 1146, 876  # real size\n",
    "    exp_scale_width = im_width_real / im_width  # 1.4325\n",
    "    exp_scale_height = im_height_real / im_height  # 1.46\n",
    "    screen_width, screen_height = 1920, 1080\n",
    "    # screen_x_cm, screen_y_cm, vp_dist_cm = 51.5, 29.0, 60\n",
    "    # sample_freq = 1000\n",
    "    # XPIX2DEG = np.arctan((screen_x_cm / screen_width) / vp_dist_cm) * (180 / np.pi)\n",
    "    # YPIX2DEG = np.arctan((screen_y_cm / screen_height) / vp_dist_cm) * (180 / np.pi)\n",
    "    # folder_name = f\"e1v{subject_num}b1\"\n",
    "    fixations = {}\n",
    "\n",
    "    # im_num = '1001.jpg'\n",
    "    # block_num = 1\n",
    "\n",
    "    BLOCK_NUMS = 40\n",
    "    for block_num in range(0, BLOCK_NUMS):\n",
    "        # block_num = 1\n",
    "        image_name = attrs_OSIE_40[block_num][\"img\"]\n",
    "        # objs = attrs_OSIE_40[block_num][\"objs\"]\n",
    "\n",
    "        fix_data_block = fix_data[fix_data[\"img\"] == image_name]\n",
    "        Cfix = len(fix_data_block)  # fixation count\n",
    "        Dfix = list(fix_data_block[\"dur\"])  # fixation durations\n",
    "        Xfix = list(\n",
    "            ((fix_data_block[\"axp\"] - (screen_width / 2)) / exp_scale_width) + (im_width / 2)\n",
    "        )\n",
    "        Order = list(fix_data_block[\"fix_order\"])\n",
    "        # Xfix = Xfix - (screen_width/2) #/ exp_scale_width)\n",
    "        # Xfix = Xfix + (im_width/2)\n",
    "        # Xfix_norm = Xfix/exp_scale_width # X coord\n",
    "        Yfix = list(\n",
    "            ((fix_data_block[\"ayp\"] - (screen_height / 2)) / exp_scale_height) + (im_height / 2)\n",
    "        )  # / exp_scale_height)  # Y coord\n",
    "        # for im_num in pd.unique(fix_data['img']):\n",
    "        # Analyze semantic content\n",
    "        sem = np.zeros((Cfix, len(dims)))\n",
    "\n",
    "        for d in range(len(dims)):\n",
    "            map_sum = np.zeros((im_height, im_width))\n",
    "            # map_ori = []\n",
    "            for obj in range(len(attrs_OSIE_40[block_num][\"objs\"])):\n",
    "                # obj = 0\n",
    "                if attrs_OSIE_40[block_num][\"objs\"][obj][\"features\"][dims[d]] > 0:\n",
    "                    # print(attrs_OSIE_40[block_num-1]['objs'][obj]['features'][dims[d]])\n",
    "                    map_ori = attrs_OSIE_40[block_num][\"objs\"][obj][\"map\"]\n",
    "                    # print(map_ori)\n",
    "                    map_sum += map_ori\n",
    "                    # print(map_sum)\n",
    "            for f in range(Cfix):\n",
    "                sem[f, d] = 0\n",
    "                if 0 < round(Xfix[f]) <= im_width and 0 < round(Yfix[f]) <= im_height:\n",
    "                    sem[f, d] = map_sum[int(round(Yfix[f])), int(round(Xfix[f]))] * Dfix[f]\n",
    "\n",
    "        fixations[image_name] = {\n",
    "            \"X\": Xfix,\n",
    "            \"Y\": Yfix,\n",
    "            # \"Onset\": Tfix,\n",
    "            \"Duration\": Dfix,\n",
    "            # \"Amplitude\": Asac,\n",
    "            \"Sem\": pd.DataFrame(sem),\n",
    "            \"Order\": Order\n",
    "            # \"Sal\": sal,\n",
    "        }\n",
    "\n",
    "    return fixations\n",
    "\n",
    "\n",
    "\n",
    "def extract_semantic_saliency_fix(subject_num):\n",
    "    # Add necessary path\n",
    "    fix_data_path = (\n",
    "        #\"/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Task_C/data/derivatives/\"\n",
    "        RESULTS_FOLDER_FIX\n",
    "        + subject_num\n",
    "        + \"_fix_data.csv\"\n",
    "    )\n",
    "\n",
    "    OSIE_data_path = OSIE_FILE #\"/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Task_C/OSIE_40/attrs_OSIE_40.mat\"\n",
    "\n",
    "    saliency_map_path = SALIENCY_MAP_DICT#\"/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Task_C/OSIE_40/saliency_map_dict.npy\"\n",
    "\n",
    "    # Load the MATLAB .mat file containing the data\n",
    "    fix_data = pd.read_csv(fix_data_path, sep=\",\")\n",
    "    # mat_data = loadmat(OSIE_data_path)\n",
    "    mat_dict = loadmat(OSIE_data_path, simplify_cells=True)\n",
    "    attrs_OSIE_40 = mat_dict[\"attrs_OSIE_40\"]\n",
    "    #saliency_map_dict = np.load(\n",
    "    #    saliency_map_path,\n",
    "    #    allow_pickle=\"TRUE\",\n",
    "    #).item()\n",
    "    saliency_map_dict = SALIENCY_MAP_DICT\n",
    "\n",
    "    # print(saliency_map_dict)\n",
    "    # df = pd.read_table(\"/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Task_C/pilot_res/pp_scan_2024_03_21_16_08.asc\")\n",
    "    # ascii_grid = np.loadtxt(\"/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Task_C/pilot_res/pp_scan_2024_03_21_16_08.asc\", skiprows=100)\n",
    "\n",
    "    # Constants and parameters\n",
    "    dims = [0, 1, 5, 7, 10]\n",
    "    # Header = [\"Text\", \"Face\", \"Taste\", \"Motion\", \"Touched\"]\n",
    "\n",
    "    im_width, im_height = 800, 600\n",
    "\n",
    "    im_width_real, im_height_real = 1146, 876  # real size\n",
    "    exp_scale_width = im_width_real / im_width  # 1.4325\n",
    "    exp_scale_height = im_height_real / im_height  # 1.46\n",
    "    screen_width, screen_height = 1920, 1080\n",
    "    # screen_x_cm, screen_y_cm, vp_dist_cm = 51.5, 29.0, 60\n",
    "    # sample_freq = 1000\n",
    "    # XPIX2DEG = np.arctan((screen_x_cm / screen_width) / vp_dist_cm) * (180 / np.pi)\n",
    "    # YPIX2DEG = np.arctan((screen_y_cm / screen_height) / vp_dist_cm) * (180 / np.pi)\n",
    "    # folder_name = f\"e1v{subject_num}b1\"\n",
    "    fixations = {}\n",
    "\n",
    "    # im_num = '1001.jpg'\n",
    "    # block_num = 1\n",
    "\n",
    "    BLOCK_NUMS = 40\n",
    "    for block_num in range(0, BLOCK_NUMS):\n",
    "        # block_num = 1\n",
    "        image_name = attrs_OSIE_40[block_num][\"img\"]\n",
    "        # objs = attrs_OSIE_40[block_num][\"objs\"]\n",
    "\n",
    "        fix_data_block = fix_data[fix_data[\"img\"] == image_name]\n",
    "        Cfix = len(fix_data_block)  # fixation count\n",
    "        Dfix = list(fix_data_block[\"dur\"])  # fixation durations\n",
    "        Xfix = list(\n",
    "            ((fix_data_block[\"axp\"] - (screen_width / 2)) / exp_scale_width) + (im_width / 2)\n",
    "        )\n",
    "        # Xfix = Xfix - (screen_width/2) #/ exp_scale_width)\n",
    "        # Xfix = Xfix + (im_width/2)\n",
    "        # Xfix_norm = Xfix/exp_scale_width # X coord\n",
    "        Yfix = list(\n",
    "            ((fix_data_block[\"ayp\"] - (screen_height / 2)) / exp_scale_height) + (im_height / 2)\n",
    "        )  # / exp_scale_height)  # Y coord\n",
    "        Order = list(fix_data_block[\"fix_order\"])\n",
    "        # for im_num in pd.unique(fix_data['img']):\n",
    "\n",
    "        # Analyze semantic content\n",
    "        sem = np.zeros((Cfix, len(dims)))\n",
    "\n",
    "        for d in range(len(dims)):\n",
    "            map_sum = np.zeros((im_height, im_width))\n",
    "            # map_ori = []\n",
    "            for obj in range(len(attrs_OSIE_40[block_num][\"objs\"])):\n",
    "                # obj = 0\n",
    "                if attrs_OSIE_40[block_num][\"objs\"][obj][\"features\"][dims[d]] > 0:\n",
    "                    # print(attrs_OSIE_40[block_num-1]['objs'][obj]['features'][dims[d]])\n",
    "                    map_ori = attrs_OSIE_40[block_num][\"objs\"][obj][\"map\"]\n",
    "                    # print(map_ori)\n",
    "                    map_sum += map_ori\n",
    "                    # print(map_sum)\n",
    "            for f in range(Cfix):\n",
    "                sem[f, d] = 0\n",
    "                if 0 < round(Xfix[f]) <= im_width and 0 < round(Yfix[f]) <= im_height:\n",
    "                    sem[f, d] = map_sum[int(round(Yfix[f])), int(round(Xfix[f]))] * Dfix[f]\n",
    "\n",
    "        sem_df = pd.DataFrame(sem)\n",
    "\n",
    "        # Analyze saliency content\n",
    "        sal = np.zeros((Cfix, len(saliency_map_dict[image_name])))\n",
    "        list_of_sal_maps = list(saliency_map_dict[image_name].keys())\n",
    "\n",
    "        for i, sal_map in enumerate(list_of_sal_maps):\n",
    "            # print(i, sal_map)\n",
    "            sal_map_ori = saliency_map_dict[image_name][sal_map]\n",
    "\n",
    "            for f in range(Cfix):\n",
    "                sal[f, i] = 0\n",
    "                if 0 < round(Xfix[f]) <= im_width and 0 < round(Yfix[f]) <= im_height:\n",
    "                    # sal[f, i] = sal_map_ori[int(round(Yfix[f])), int(round(Xfix[f]))] * Dfix[f]\n",
    "                    sal[f, i] = (\n",
    "                        np.sum(sal_map_ori < sal_map_ori[int(round(Yfix[f])), int(round(Xfix[f]))])\n",
    "                        / sal_map_ori.size\n",
    "                    )  # * Dfix[f]\n",
    "\n",
    "        sal_df = pd.DataFrame(sal, columns=list_of_sal_maps)\n",
    "\n",
    "        fixations[image_name] = {\n",
    "            \"X\": Xfix,\n",
    "            \"Y\": Yfix,\n",
    "            # \"Onset\": Tfix,\n",
    "            \"Duration\": Dfix,\n",
    "            # \"Amplitude\": Asac,\n",
    "            \"Sem\": sem_df,\n",
    "            \"Sal\": sal_df,\n",
    "            \"Order\": Order,\n",
    "        }\n",
    "\n",
    "    return fixations\n",
    "\n",
    "\n",
    "\n",
    "def plot_fixations_semantic_group():\n",
    "    # subject_list = ['zt','pp','jp']\n",
    "    sem_fix_dataframe_group = pd.DataFrame()\n",
    "    for subject_num in SUBJECT_LIST:\n",
    "        \n",
    "        # subject_num='zt'\n",
    "        fixations = extract_semantic_saliency_fix(subject_num)\n",
    "        # Constants and parameters\n",
    "        dims = [0, 1, 5, 7, 10]\n",
    "        header = [\"Text\", \"Face\", \"Taste\", \"Motion\", \"Touched\"]\n",
    "    \n",
    "        first_fix = []\n",
    "        all_fix = pd.DataFrame()\n",
    "        # d_fix = []\n",
    "        all_dur = []  # pd.DataFrame()\n",
    "        fixation_keys = list(fixations.keys())\n",
    "    \n",
    "        for key in fixation_keys:\n",
    "            # key = '1001.jpg'\n",
    "            if fixations[key] is not None:\n",
    "                first_fix.append(fixations[key][\"Sem\"].iloc[0])\n",
    "    \n",
    "                df_sem = pd.DataFrame(fixations[key][\"Sem\"])\n",
    "                df_dur = fixations[key][\"Duration\"]\n",
    "    \n",
    "                all_fix = pd.concat([all_fix, df_sem])\n",
    "                all_dur += df_dur\n",
    "    \n",
    "        first_prop = np.sum(np.sign(first_fix), axis=0) / len(first_fix)\n",
    "        # all_prop = np.sum(all_fix, axis=0) / np.sum(d_fix)\n",
    "        all_prop = all_fix.sum() / sum(all_dur)\n",
    "\n",
    "        # sem_fix_data = pd.DataFrame((np.array(header), first_prop, np.array(all_prop))).T.rename(columns={0:'header', 1:'first_prop', 2:'all_prop'})\n",
    "        sem_fix_data = {\"header\": header, \"first_prop\": list(first_prop), \"all_prop\": list(all_prop)}\n",
    "        sem_fix_dataframe_ind = pd.DataFrame(sem_fix_data, columns=[\"header\", \"first_prop\", \"all_prop\"])\n",
    "        sem_fix_dataframe_ind['sub_num'] = subject_num\n",
    "        \n",
    "        sem_fix_dataframe_group = pd.concat([sem_fix_dataframe_group, sem_fix_dataframe_ind])\n",
    "\n",
    "        \n",
    "    # Defining the x-axis, the y-axis and the data\n",
    "    # from where the values are to be taken\n",
    "    fig, ax = plt.subplots(figsize=(12, 5), ncols=2)\n",
    "    for i, y_value in enumerate([\"first_prop\", \"all_prop\"]):\n",
    "        sns.barplot(x=\"header\", y=y_value, data=sem_fix_dataframe_group, ax=ax[i], color='grey', alpha=0.7)\n",
    "        sns.stripplot(x=\"header\", y=y_value, data=sem_fix_dataframe_group, ax=ax[i], hue='sub_num', dodge=True)#color='grey')\n",
    "        ax[i].set_ylim([0, 1])\n",
    "        ax[i].tick_params(axis=\"x\", rotation=45)\n",
    "        ax[i].set_axisbelow(True)\n",
    "        ax[i].set_xlabel(\"Semantic category\", size=15)\n",
    "        ax[i].grid(True)\n",
    "        if i == 0:\n",
    "            ax[i].set_ylabel(\"Proportion of fixations\", size=15)\n",
    "            ax[0].set_title(\"First fixation [Group]\")\n",
    "        else:\n",
    "            ax[i].set_ylabel(\"Proportion of cumulative fixation duration\", size=15)\n",
    "            ax[1].set_title(\"All fixations [Group]\")\n",
    "\n",
    "    ax[0].legend().set_visible(False)\n",
    "    ax[1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0).set_visible(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_fixations_salience_group():\n",
    "    #subject_list = [\"zt\", \"pp\", \"jp\"]\n",
    "    sal_fix_dataframe_group = pd.DataFrame()\n",
    "    for subject_num in SUBJECT_LIST:\n",
    "        # fixations = extract_semantic_fix(subject_num)\n",
    "        fixations = extract_semantic_saliency_fix(subject_num)\n",
    "        # Constants and parameters\n",
    "        header = [\"Saliency\", \"Intensity\", \"Color\", \"Orientation\"]\n",
    "\n",
    "        first_fix = []  # pd.DataFrame()\n",
    "        all_fix = pd.DataFrame()\n",
    "        fixation_keys = list(fixations.keys())\n",
    "\n",
    "        for key in fixation_keys:\n",
    "            if fixations[key] is not None:\n",
    "                first_fix.append(fixations[key][\"Sal\"].iloc[0])\n",
    "                df_sal = fixations[key][\"Sal\"]\n",
    "                all_fix = pd.concat([all_fix, df_sal])\n",
    "\n",
    "        first_fix_df = pd.DataFrame(first_fix)\n",
    "        first_prop = first_fix_df.mean()\n",
    "        all_prop = all_fix.mean()\n",
    "\n",
    "        # sem_fix_data = pd.DataFrame((np.array(header), first_prop, np.array(all_prop))).T.rename(columns={0:'header', 1:'first_prop', 2:'all_prop'})\n",
    "        sal_fix_data = {\n",
    "            \"header\": header,\n",
    "            \"first_prop\": list(first_prop),\n",
    "            \"all_prop\": list(all_prop),\n",
    "        }\n",
    "        sal_fix_dataframe_ind = pd.DataFrame(\n",
    "            sal_fix_data, columns=[\"header\", \"first_prop\", \"all_prop\"]\n",
    "        )\n",
    "\n",
    "        sal_fix_dataframe_ind[\"sub_num\"] = subject_num\n",
    "\n",
    "        sal_fix_dataframe_group = pd.concat([sal_fix_dataframe_group, sal_fix_dataframe_ind])\n",
    "\n",
    "    # Defining the x-axis, the y-axis and the data\n",
    "    # from where the values are to be taken\n",
    "    fig, ax = plt.subplots(figsize=(12, 5), ncols=2)\n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    for i, y_value in enumerate([\"first_prop\", \"all_prop\"]):\n",
    "        sns.barplot(\n",
    "            x=\"header\", y=y_value, data=sal_fix_dataframe_group, ax=ax[i], color=\"grey\", alpha=0.7\n",
    "        )\n",
    "        sns.stripplot(\n",
    "            x=\"header\", y=y_value, data=sal_fix_dataframe_group, ax=ax[i], hue=\"sub_num\", dodge=True\n",
    "        )  # color='grey')\n",
    "        ax[i].set_ylim([0, 1])\n",
    "        ax[i].tick_params(axis=\"x\", rotation=45)\n",
    "        ax[i].set_axisbelow(True)\n",
    "        ax[i].set_xlabel(\"Saliency feature\", size=15)\n",
    "        ax[i].grid(True)\n",
    "        if i == 0:\n",
    "            ax[i].set_ylabel(\"Percent fixated\", size=15)\n",
    "            ax[0].set_title(\"First fixation [Group]\")\n",
    "        else:\n",
    "            ax[i].set_ylabel(\"Percent fixated\", size=15)\n",
    "            ax[1].set_title(\"All fixations [Group]\")\n",
    "\n",
    "    ax[0].legend().set_visible(False)\n",
    "    ax[1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0).set_visible(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_fixations_semantic_group_plotly():\n",
    "    # subject_list = ['zt','pp','jp']\n",
    "    sem_fix_dataframe_group = pd.DataFrame()\n",
    "    for subject_num in SUBJECT_LIST:\n",
    "        \n",
    "        # subject_num='zt'\n",
    "        fixations = extract_semantic_saliency_fix(subject_num)\n",
    "        # Constants and parameters\n",
    "        dims = [0, 1, 5, 7, 10]\n",
    "        header = [\"Text\", \"Face\", \"Taste\", \"Motion\", \"Touched\"]\n",
    "    \n",
    "        first_fix = []\n",
    "        all_fix = pd.DataFrame()\n",
    "        # d_fix = []\n",
    "        all_dur = []  # pd.DataFrame()\n",
    "        fixation_keys = list(fixations.keys())\n",
    "    \n",
    "        for key in fixation_keys:\n",
    "            # key = '1001.jpg'\n",
    "            if fixations[key] is not None:\n",
    "                first_fix.append(fixations[key][\"Sem\"].iloc[0])\n",
    "    \n",
    "                df_sem = pd.DataFrame(fixations[key][\"Sem\"])\n",
    "                df_dur = fixations[key][\"Duration\"]\n",
    "    \n",
    "                all_fix = pd.concat([all_fix, df_sem])\n",
    "                all_dur += df_dur\n",
    "    \n",
    "        first_prop = np.sum(np.sign(first_fix), axis=0) / len(first_fix)\n",
    "        # all_prop = np.sum(all_fix, axis=0) / np.sum(d_fix)\n",
    "        all_prop = all_fix.sum() / sum(all_dur)\n",
    "\n",
    "        # sem_fix_data = pd.DataFrame((np.array(header), first_prop, np.array(all_prop))).T.rename(columns={0:'header', 1:'first_prop', 2:'all_prop'})\n",
    "        sem_fix_data = {\"header\": header, \"first_prop\": list(first_prop), \"all_prop\": list(all_prop)}\n",
    "        sem_fix_dataframe_ind = pd.DataFrame(sem_fix_data, columns=[\"header\", \"first_prop\", \"all_prop\"])\n",
    "        sem_fix_dataframe_ind['sub_num'] = subject_num\n",
    "        \n",
    "        sem_fix_dataframe_group = pd.concat([sem_fix_dataframe_group, sem_fix_dataframe_ind])\n",
    "   \n",
    "    # Create subplots with two columns\n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=(\"First fixation [Group]\", \"All fixations [Group]\"))\n",
    "    \n",
    "    # Define colors for the stripplot\n",
    "    colors = px.colors.qualitative.Safe\n",
    "    \n",
    "    # First subplot\n",
    "    y_value = \"first_prop\"\n",
    "    # Group by header and calculate mean for each category\n",
    "    group_averages = sem_fix_dataframe_group.groupby('header')[y_value].mean().reset_index()\n",
    "    # Get the order of categories from the header\n",
    "    category_order = group_averages[\"header\"].tolist()\n",
    "    # Barplot with error bars\n",
    "    fig.add_trace(go.Bar(x=group_averages[\"header\"], y=group_averages[y_value],\n",
    "                         name=y_value, marker_color='grey', opacity=0.7,\n",
    "                         error_y=dict(type='data', array=sem_fix_dataframe_group.groupby('header')[y_value].sem().tolist())),\n",
    "                  row=1, col=1)\n",
    "    # Stripplot\n",
    "    for j, sub_num in enumerate(sem_fix_dataframe_group['sub_num'].unique()):\n",
    "        fig.add_trace(go.Scatter(x=sem_fix_dataframe_group[sem_fix_dataframe_group['sub_num']==sub_num]['header'],\n",
    "                                  y=sem_fix_dataframe_group[sem_fix_dataframe_group['sub_num']==sub_num][y_value],\n",
    "                                  mode='markers',\n",
    "                                  name='Subgroup ' + str(sub_num),\n",
    "                                  marker=dict(color=colors[j]),\n",
    "                                  legendgroup='subgroup_'+str(sub_num)), row=1, col=1)\n",
    "    # Update layout\n",
    "    fig.update_xaxes(title_text=\"Semantic category\", row=1, col=1, categoryorder='array', categoryarray=category_order)\n",
    "    fig.update_yaxes(title_text=\"Proportion of fixations\", row=1, col=1, range=[0, 1])\n",
    "    fig.update_layout(xaxis_tickangle=45, plot_bgcolor='white', xaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'), yaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'))\n",
    "    fig.update_layout(title_text=\"Fixation Proportion by Semantic Category\")\n",
    "    #fig.update_layout(plot_bgcolor='white', xaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'),\n",
    "    #              yaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'))\n",
    "    \n",
    "    # Second subplot\n",
    "    y_value = \"all_prop\"\n",
    "    # Group by header and calculate mean for each category\n",
    "    group_averages = sem_fix_dataframe_group.groupby('header')[y_value].mean().reset_index()\n",
    "    # Get the order of categories from the header\n",
    "    category_order = group_averages[\"header\"].tolist()\n",
    "    # Barplot with error bars\n",
    "    fig.add_trace(go.Bar(x=group_averages[\"header\"], y=group_averages[y_value],\n",
    "                         name=y_value, marker_color='grey', opacity=0.7,\n",
    "                         error_y=dict(type='data', array=sem_fix_dataframe_group.groupby('header')[y_value].sem().tolist())),\n",
    "                  row=1, col=2)\n",
    "    # Stripplot\n",
    "    for j, sub_num in enumerate(sem_fix_dataframe_group['sub_num'].unique()):\n",
    "        fig.add_trace(go.Scatter(x=sem_fix_dataframe_group[sem_fix_dataframe_group['sub_num']==sub_num]['header'],\n",
    "                                  y=sem_fix_dataframe_group[sem_fix_dataframe_group['sub_num']==sub_num][y_value],\n",
    "                                  mode='markers',\n",
    "                                  name='Subgroup ' + str(sub_num),\n",
    "                                  marker=dict(color=colors[j]),\n",
    "                                  legendgroup='subgroup_'+str(sub_num)), row=1, col=2)\n",
    "    # Update layout\n",
    "    fig.update_xaxes(title_text=\"Semantic category\", row=1, col=2, categoryorder='array', categoryarray=category_order)\n",
    "    fig.update_yaxes(title_text=\"Proportion of cumulative fixation duration\", row=1, col=2, range=[0, 1])\n",
    "    fig.update_layout(xaxis_tickangle=45, plot_bgcolor='white', xaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'), yaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'))\n",
    "    #fig.update_layout(plot_bgcolor='white', xaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'),\n",
    "    #              yaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'))\n",
    "    \n",
    "    # Show plot\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_fixations_salience_group_plotly():\n",
    "    subject_list = [\"zt\", \"pp\", \"jp\"]\n",
    "    sal_fix_dataframe_group = pd.DataFrame()\n",
    "    saliency_features = [\"Saliency\", \"Intensity\", \"Color\", \"Orientation\"]\n",
    "    \n",
    "    for subject_num in subject_list:\n",
    "        fixations = extract_semantic_saliency_fix(subject_num)\n",
    "\n",
    "        first_fix = []\n",
    "        all_fix = pd.DataFrame()\n",
    "        fixation_keys = list(fixations.keys())\n",
    "\n",
    "        for key in fixation_keys:\n",
    "            if fixations[key] is not None:\n",
    "                first_fix.append(fixations[key][\"Sal\"].iloc[0])\n",
    "                df_sal = fixations[key][\"Sal\"]\n",
    "                all_fix = pd.concat([all_fix, df_sal])\n",
    "\n",
    "        first_fix_df = pd.DataFrame(first_fix)\n",
    "        first_prop = first_fix_df.mean()\n",
    "        all_prop = all_fix.mean()\n",
    "\n",
    "        sal_fix_data = {\n",
    "            \"header\": saliency_features,\n",
    "            \"first_prop\": list(first_prop),\n",
    "            \"all_prop\": list(all_prop),\n",
    "        }\n",
    "        sal_fix_dataframe_ind = pd.DataFrame(\n",
    "            sal_fix_data, columns=[\"header\", \"first_prop\", \"all_prop\"]\n",
    "        )\n",
    "\n",
    "        sal_fix_dataframe_ind[\"sub_num\"] = subject_num\n",
    "\n",
    "        sal_fix_dataframe_group = pd.concat([sal_fix_dataframe_group, sal_fix_dataframe_ind])\n",
    "\n",
    " # Create subplots with two columns\n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=(\"First fixation [Group]\", \"All fixations [Group]\"))\n",
    "    \n",
    "    # Define colors for the stripplot\n",
    "    colors = px.colors.qualitative.Safe\n",
    "    \n",
    "    # First subplot\n",
    "    y_value = \"first_prop\"\n",
    "    # Group by header and calculate mean for each category\n",
    "    group_averages = sal_fix_dataframe_group.groupby('header')[y_value].mean().reset_index()\n",
    "    # Get the order of categories from the header\n",
    "    category_order = group_averages[\"header\"].tolist()\n",
    "    # Barplot with error bars\n",
    "    fig.add_trace(go.Bar(x=group_averages[\"header\"], y=group_averages[y_value],\n",
    "                         name=y_value, marker_color='grey', opacity=0.7,\n",
    "                         error_y=dict(type='data', array=sal_fix_dataframe_group.groupby('header')[y_value].sem().tolist())),\n",
    "                  row=1, col=1)\n",
    "    # Stripplot\n",
    "    for j, sub_num in enumerate(sal_fix_dataframe_group['sub_num'].unique()):\n",
    "        fig.add_trace(go.Scatter(x=sal_fix_dataframe_group[sal_fix_dataframe_group['sub_num']==sub_num]['header'],\n",
    "                                  y=sal_fix_dataframe_group[sal_fix_dataframe_group['sub_num']==sub_num][y_value],\n",
    "                                  mode='markers',\n",
    "                                  name='Subgroup ' + str(sub_num),\n",
    "                                  marker=dict(color=colors[j]),\n",
    "                                  legendgroup='subgroup_'+str(sub_num)), row=1, col=1)\n",
    "    # Update layout\n",
    "    fig.update_xaxes(title_text=\"Salience feature\", row=1, col=1, categoryorder='array', categoryarray=category_order)\n",
    "    fig.update_yaxes(title_text=\"Proportion of fixations\", row=1, col=1, range=[0, 1])\n",
    "    fig.update_layout(xaxis_tickangle=45, plot_bgcolor='white', xaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'), yaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'))\n",
    "    fig.update_layout(title_text=\"Fixation Proportion by Salience Feature\")\n",
    "    #fig.update_layout(plot_bgcolor='white', xaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'),\n",
    "    #              yaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'))\n",
    "\n",
    "    # Second subplot\n",
    "    y_value = \"all_prop\"\n",
    "    # Group by header and calculate mean for each category\n",
    "    group_averages = sal_fix_dataframe_group.groupby('header')[y_value].mean().reset_index()\n",
    "    # Get the order of categories from the header\n",
    "    category_order = group_averages[\"header\"].tolist()\n",
    "    # Barplot with error bars\n",
    "    fig.add_trace(go.Bar(x=group_averages[\"header\"], y=group_averages[y_value],\n",
    "                         name=y_value, marker_color='grey', opacity=0.7,\n",
    "                         error_y=dict(type='data', array=sal_fix_dataframe_group.groupby('header')[y_value].sem().tolist())),\n",
    "                  row=1, col=2)\n",
    "    # Stripplot\n",
    "    for j, sub_num in enumerate(sal_fix_dataframe_group['sub_num'].unique()):\n",
    "        fig.add_trace(go.Scatter(x=sal_fix_dataframe_group[sal_fix_dataframe_group['sub_num']==sub_num]['header'],\n",
    "                                  y=sal_fix_dataframe_group[sal_fix_dataframe_group['sub_num']==sub_num][y_value],\n",
    "                                  mode='markers',\n",
    "                                  name='Subgroup ' + str(sub_num),\n",
    "                                  marker=dict(color=colors[j]),\n",
    "                                  legendgroup='subgroup_'+str(sub_num)), row=1, col=2)\n",
    "    # Update layout\n",
    "    fig.update_xaxes(title_text=\"Salience feature\", row=1, col=2, categoryorder='array', categoryarray=category_order)\n",
    "    fig.update_yaxes(title_text=\"Proportion of cumulative fixation duration\", row=1, col=2, range=[0, 1])\n",
    "    fig.update_layout(xaxis_tickangle=45, plot_bgcolor='white', xaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'), yaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'))\n",
    "    #fig.update_layout(plot_bgcolor='white', xaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'),\n",
    "    #              yaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'))\n",
    "    \n",
    "    # Show plot\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_heatmap_group():\n",
    "    im_width = 800\n",
    "    im_height = 600\n",
    "    \n",
    "    first_map_group = np.zeros((im_height, im_width))\n",
    "    all_map_group = np.zeros((im_height, im_width))\n",
    "    whole_duration_group = 0\n",
    "    fixation_count = 0\n",
    "    subject_list = ['zt','pp','jp']\n",
    "    for subject_num in subject_list:\n",
    "\n",
    "    # Load fixations data from .mat file\n",
    "        fixations = extract_semantic_saliency_fix(subject_num) #subject_num\n",
    "    \n",
    "        x = np.arange(1, im_width + 1)\n",
    "        y = np.arange(1, im_height + 1)\n",
    "        x, y = np.meshgrid(x, y)\n",
    "    \n",
    "        first_map = np.zeros((im_height, im_width))\n",
    "        all_map = np.zeros((im_height, im_width))\n",
    "        fix_num = 0\n",
    "        whole_duration = 0\n",
    "        fixation_count += len(fixations)\n",
    "        \n",
    "        for key in fixations.keys():\n",
    "            # key = '1001.jpg'\n",
    "            if fixations[key] is not None:\n",
    "                for f in range(len(fixations[key][\"X\"])):\n",
    "                    ex = fixations[key][\"X\"][f]\n",
    "                    ey = fixations[key][\"Y\"][f]\n",
    "                    duration = fixations[key][\"Duration\"][f]\n",
    "                    # whole_duration += duration\n",
    "                    whole_duration_group += duration\n",
    "                    dx = x - ex\n",
    "                    dy = y - ey\n",
    "                    r = np.hypot(dx, dy)\n",
    "                    # all_map += duration * norm.pdf(r, 0, 30) / norm.pdf(0, 0, 30)\n",
    "                    all_map_group += duration * norm.pdf(r, 0, 30) / norm.pdf(0, 0, 30)\n",
    "                    fix_num += 1\n",
    "                    if f == 0:\n",
    "                        # first_map += norm.pdf(r, 0, 30) / norm.pdf(0, 0, 30)\n",
    "                        first_map_group += norm.pdf(r, 0, 30) / norm.pdf(0, 0, 30)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    first_map_group /= fixation_count#len(fixations)\n",
    "    axs[0].imshow(first_map_group, cmap=\"viridis\")\n",
    "    axs[0].plot([0, im_width], [im_height / 2, im_height / 2], \"w--\")\n",
    "    axs[0].plot([im_width / 2, im_width / 2], [0, im_height], \"w--\")\n",
    "    axs[0].set_title(\"First fixation [Group]\")\n",
    "    axs[0].set_xticklabels([])\n",
    "    axs[0].set_yticklabels([])\n",
    "    axs[0].set_ylim(im_height, 0)  # Reverse y-axis\n",
    "    plt.colorbar(axs[0].imshow(first_map_group, cmap=\"viridis\"), ax=axs[0], location='bottom')\n",
    "\n",
    "    all_map_group /= whole_duration_group\n",
    "    all_map_smoothed = gaussian_filter(all_map_group, sigma=2)  # Adjust sigma as needed\n",
    "    axs[1].imshow(all_map_smoothed, cmap=\"viridis\")  # Use the smoothed map\n",
    "    axs[1].plot([0, im_width], [im_height / 2, im_height / 2], \"w--\")\n",
    "    axs[1].plot([im_width / 2, im_width / 2], [0, im_height], \"w--\")\n",
    "    axs[1].set_title(\"All fixations (Smoothed) [Group]\")\n",
    "    axs[1].set_xticklabels([])\n",
    "    axs[1].set_yticklabels([])\n",
    "    axs[1].set_ylim(im_height, 0)  # Reverse y-axis\n",
    "    plt.colorbar(axs[1].imshow(all_map_smoothed, cmap=\"viridis\"), ax=axs[1], location = 'bottom')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_eye_movement_distributions_group():\n",
    "    fix_data_group = pd.DataFrame()\n",
    "    sacc_data_group = pd.DataFrame()\n",
    "    \n",
    "    subject_list = SUBJECT_LIST\n",
    "    \n",
    "    for subject_num in subject_list:\n",
    "    \n",
    "        fix_data_path = (\n",
    "            #\"/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Task_C/data/derivatives/\"\n",
    "            RESULTS_FOLDER_FIX\n",
    "            + subject_num\n",
    "            + \"_fix_data.csv\"\n",
    "        )\n",
    "        fix_data_ind = pd.read_csv(fix_data_path, sep=\",\")\n",
    "        fix_data_ind['sub_num'] = subject_num\n",
    "        \n",
    "        sacc_data_path = (\n",
    "            #\"/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Task_C/data/derivatives/\"\n",
    "            RESULTS_FOLDER_SACC\n",
    "            + subject_num\n",
    "            + \"_sacc_data.csv\"\n",
    "        )\n",
    "        sacc_data_ind = pd.read_csv(sacc_data_path, sep=\",\")\n",
    "        sacc_data_ind['sub_num'] = subject_num\n",
    "\n",
    "        fix_data_group = pd.concat([fix_data_group, fix_data_ind])\n",
    "        sacc_data_group = pd.concat([sacc_data_group, sacc_data_ind])\n",
    "    \n",
    "    # fig_dur = sns.ecdfplot(data=fix_data_group, x='dur', hue='sub_num')\n",
    "    # fig_dur.set_xlabel(\"Fixation duration [s]\")\n",
    "    # fig_dur.set_ylabel(\"Cumulative proportion\")\n",
    "    # fig_dur.set_title(\"Fixation Duration Distribution\")\n",
    "    # plt.show()\n",
    "    \n",
    "    # fig_ampli = sns.ecdfplot(data=sacc_data_group, x='ampl', hue='sub_num')\n",
    "    # fig_ampli.set_xlabel(\"Fixation duration [s]\")\n",
    "    # fig_ampli.set_ylabel(\"Cumulative proportion\")\n",
    "    # fig_ampli.set_title(\"Fixation Duration Distribution\")\n",
    "    # plt.show()\n",
    "\n",
    "    fig, axs = plt.subplots(2,1)\n",
    "    plt.subplot(2, 1, 1)\n",
    "    sns.boxplot(fix_data_group['dur'], showmeans=True)\n",
    "    axs[0].set(xticklabels=[])\n",
    "    axs[0].set_title(\"Fixation Duration Distribution [Group]\")\n",
    "    plt.subplot(2, 1, 2)\n",
    "    sns.ecdfplot(data=fix_data_group, x='dur', color='blue', hue='sub_num')\n",
    "    axs[1].set_xlabel(\"Fixation duration [s]\")\n",
    "    axs[1].set_ylabel(\"Cumulative proportion\")\n",
    "    plt.show()\n",
    "    \n",
    "    fig, axs = plt.subplots(2,1)\n",
    "    plt.subplot(2, 1, 1)\n",
    "    sns.boxplot(sacc_data_group['ampl'], showmeans=True, color='orange')\n",
    "    axs[0].set(xticklabels=[])\n",
    "    axs[0].set_title(\"Saccade Amplitude Distribution [Group]\")\n",
    "    plt.subplot(2, 1, 2)\n",
    "    sns.ecdfplot(data=sacc_data_group, x='ampl', color='orange', hue='sub_num')\n",
    "    axs[1].set_xlabel(\"Saccade amplitude [deg]\")\n",
    "    axs[1].set_ylabel(\"Cumulative proportion\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_eye_movement_distributions_group_plotly():\n",
    "    fix_data_group = pd.DataFrame()\n",
    "    sacc_data_group = pd.DataFrame()\n",
    "    \n",
    "    subject_list = SUBJECT_LIST\n",
    "    \n",
    "    for subject_num in subject_list:\n",
    "    \n",
    "        fix_data_path = (\n",
    "            #\"/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Task_C/data/derivatives/\"\n",
    "            RESULTS_FOLDER_FIX\n",
    "            + subject_num\n",
    "            + \"_fix_data.csv\"\n",
    "        )\n",
    "        fix_data_ind = pd.read_csv(fix_data_path, sep=\",\")\n",
    "        fix_data_ind['sub_num'] = subject_num\n",
    "        \n",
    "        sacc_data_path = (\n",
    "            #\"/Users/patrikpolgari/Documents/Postdoc_Marburg/student_supervision/Teaching/B-NP2_Übung/Code/Task_C/data/derivatives/\"\n",
    "            RESULTS_FOLDER_SACC\n",
    "            + subject_num\n",
    "            + \"_sacc_data.csv\"\n",
    "        )\n",
    "        sacc_data_ind = pd.read_csv(sacc_data_path, sep=\",\")\n",
    "        sacc_data_ind['sub_num'] = subject_num\n",
    "\n",
    "        fix_data_group = pd.concat([fix_data_group, fix_data_ind])\n",
    "        sacc_data_group = pd.concat([sacc_data_group, sacc_data_ind])\n",
    "        \n",
    "    # Plotly doesn't have built-in support for boxplots, so we'll use a violin plot instead\n",
    "    fig1 = make_subplots(rows=2, cols=1, subplot_titles=(\"Fixation Duration Distribution [Group]\", \"Cumulative Duration [Group]\"))\n",
    "    \n",
    "    # Violin plot for fixation duration distribution\n",
    "    fig1.add_trace(go.Violin(x=fix_data_group['dur'], box_visible=True, meanline_visible=True, showlegend=False, orientation='h'), row=1, col=1)\n",
    "\n",
    "    # ECDF plot for cumulative proportion\n",
    "    ecdf_fig1 = px.ecdf(fix_data_group, x='dur', color='sub_num')\n",
    "    for trace in ecdf_fig1.data:\n",
    "        fig1.add_trace(trace, row=2, col=1)\n",
    "        fig1.update_layout(plot_bgcolor='white', xaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'),\n",
    "                  yaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'))\n",
    "        \n",
    "    \n",
    "    # Update layout\n",
    "    fig1.update_layout(height=600, width=800)#, title_text=\"Fixation Duration Distribution and Cumulative Duration\")\n",
    "    # Set the background color to white\n",
    "    fig1.update_layout(plot_bgcolor='white', xaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'),\n",
    "                  yaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'))\n",
    "    \n",
    "    # Update axes\n",
    "    fig1.update_xaxes(title_text=\"Fixation duration [s]\", row=2, col=1)\n",
    "    fig1.update_yaxes(title_text=\"Cumulative proportion\", row=2, col=1)\n",
    "    \n",
    "    # Show plot\n",
    "    fig1.show()\n",
    "\n",
    "    \n",
    "    #Plotly doesn't have built-in support for boxplots, so we'll use a violin plot instead\n",
    "    fig2 = make_subplots(rows=2, cols=1, subplot_titles=(\"Saccade Amplitude Distribution [Group]\", \"Cumulative proportion [Group]\"))\n",
    "    \n",
    "    # Violin plot for fixation duration distribution\n",
    "    fig2.add_trace(go.Violin(x=sacc_data_group['ampl'], box_visible=True, meanline_visible=True, showlegend=False, orientation='h', line_color='orange'), row=1, col=1)\n",
    "\n",
    "    # ECDF plot for cumulative proportion\n",
    "    ecdf_fig2 = px.ecdf(sacc_data_group, x='ampl', color='sub_num')\n",
    "    for trace in ecdf_fig2.data:\n",
    "        fig2.add_trace(trace, row=2, col=1)\n",
    "        fig2.update_layout(plot_bgcolor='white', xaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'),\n",
    "                  yaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'))\n",
    "        \n",
    "    \n",
    "    # Update layout\n",
    "    fig2.update_layout(height=600, width=800)#, title_text=\"Saccade Amplitude Distribution and Cumulative Duration\")\n",
    "    # Set the background color to white\n",
    "    fig2.update_layout(plot_bgcolor='white', xaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'),\n",
    "                  yaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGrey'))\n",
    "    \n",
    "    # Update axes\n",
    "    fig2.update_xaxes(title_text=\"Saccade amplitude [deg]\", row=2, col=1)\n",
    "    fig2.update_yaxes(title_text=\"Cumulative proportion\", row=2, col=1)\n",
    "    \n",
    "    # Show plot\n",
    "    fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e00e2b-09ec-451f-bed1-8d648c844f74",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_fixations_semantic_group()\n",
    "#plot_fixations_semantic_group_plotly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eace77-e0e9-4a92-a3af-bb31ca1c9538",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_fixations_salience_group()\n",
    "#plot_fixations_salience_group_plotly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb930c0b-d10f-41c5-907a-49ce74d9c015",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_eye_movement_distributions_group_plotly()\n",
    "#plot_eye_movement_distributions_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694b73c9-9a91-4d9b-a8d9-04e71146c6a7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_heatmap_group()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec336980-5f3f-4e08-8b1f-c196ac6c8dea",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c805df9-f884-4240-b69a-71762bd0a291",
   "metadata": {},
   "source": [
    "<font size=5>Step 2: The role of instructions\n",
    "\n",
    "<font size=3>Think about the instructions of the task. \n",
    "\n",
    "<font size=3>•\tHow do you think instructions relate to the different measurements we studied? \n",
    "\n",
    "<font size=3>•\tWhat other instructions could have been given in the task with the present set of images (1-2 examples)? \n",
    "\n",
    "<font size=3>•\tMake hypotheses about the potential results and how they would be similar/different from your own/the group’s results.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
